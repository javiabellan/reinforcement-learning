# Deep Reinforcement learning


## Part 1: Q Value based

<table>
  <tr>
    <th></th>
    <th>Name</th>
    <th>Paper</th>
    <th rowspan="9"><img align="right" width="330" src="/img/rainbow.png"></th>
  </tr>
  
  <tr> <td>Baseline </td>  <td>DQN: Deep Q Learning</td>  <td><a href="https://arxiv.org/abs/1312.5602 ">2013</a></td> </tr>
  <tr> <td>Improv. 1</td>  <td>Double DQN  (DDQN)  </td>  <td><a href="https://arxiv.org/abs/1509.06461">2015</a></td> </tr>
  <tr> <td>Improv. 2</td>  <td>Prioritized DQN     </td>  <td><a href="https://arxiv.org/abs/1511.05952">2015</a></td> </tr>
  <tr> <td>Improv. 3</td>  <td>Dueling DQN         </td>  <td><a href="https://arxiv.org/abs/1511.06581">2015</a></td> </tr>
  <tr> <td>Improv. 4</td>  <td>A3C                 </td>  <td><a href="https://arxiv.org/abs/1602.01783">2016</a></td> </tr>
  <tr> <td>Improv. 5</td>  <td>Noisy DQN           </td>  <td><a href="https://arxiv.org/abs/1706.10295">2017</a></td> </tr>
  <tr> <td>Improv. 6</td>  <td>Distributional DQN  </td>  <td><a href="https://arxiv.org/abs/1707.06887">2017</a></td> </tr>
  <tr> <td>Combine 6</td>  <td>Rainbow             </td>  <td><a href="https://arxiv.org/abs/1710.02298">2017</a></td> </tr>
</table>



## Part 2: Policy Gradient based

| Name                                                      | Paper                                    |
|-----------------------------------------------------------|------------------------------------------|
| **VPG**: Vanilla Policy Gradient (aka REINFORCE)          | [1992](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf) |
| **DDPG**: Deep Deterministic Policy Gradients             | [2015](https://arxiv.org/abs/1509.02971) |
| **A2C**: Advantage Actor Critic                           |                                          |
| **A3C**: Asynchronous Advantage Actor Critic              | [2016](https://arxiv.org/abs/1602.01783) |
| **PPO**: Proximal Policy Optimisation                     | [2017](https://arxiv.org/abs/1707.06347) |
| **TD3**: Twin Delayed Deep Deterministic Policy Gradients | [2018](https://arxiv.org/abs/1802.09477) |
| **SAC**: Soft Actor-Critic                                | [2018](https://arxiv.org/abs/1812.05905) |
| **SAC-Discrete**: Soft Actor-Critic for Discrete Actions  | [2019](https://arxiv.org/abs/1910.07207) |

## References

- [**Udacity RL repo**](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn/solution)
- [**RL-Adventure 1**](https://github.com/higgsfield/RL-Adventure)
- [**RL-Adventure 2**](https://github.com/higgsfield/RL-Adventure-2)
- [**OpenAI Spinning Up**](https://spinningup.openai.com)
- [**Pytorch tutorial DQN**](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)
- [17 algos pytorch](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch)

